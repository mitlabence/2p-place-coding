{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.getipython import get_ipython\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import h5py\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "sys.path.append(\"..\")\n",
    "from placecode import utils as ut\n",
    "from placecode.from_caiman import *\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "        get_ipython().run_line_magic('autoreload', '2')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: sankey diagram to plot how cells behave over recordings, e.g. place cell, no place cell, still place cell, still no place cell\n",
    "# TODO: do a heatmap plotting all persistent cells (that made through analysis): each column is condition, each row contains same cell spatial component.\n",
    "# TODO: work on the % of cells analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open (hdf5) files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list = []\n",
    "while True:\n",
    "    fpath = ut.open_file(\"Open hdf5 file, or press Cancel to finish\")\n",
    "    if fpath == \".\":  # user pressed cancel\n",
    "        break\n",
    "    else:\n",
    "        files_list.append(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_list = []\n",
    "A_list = []\n",
    "dims_list = []  # Cn entry in workspace # TODO: A_sparse always have lower resolution, probably from cropping... should I define that as dims?\n",
    "templates = []\n",
    "p_vals = []\n",
    "conditions = []\n",
    "tv_angles = []\n",
    "tv_lengths = []\n",
    "for fpath in files_list:\n",
    "    with h5py.File(fpath, \"r\") as hf:\n",
    "        resolution = hf.attrs[\"resolution\"][()]\n",
    "        n_components = hf.attrs[\"n_units\"]\n",
    "        condition = hf.attrs[\"condition\"]\n",
    "        ps = hf[\"p_values_tuned\"][()]\n",
    "        A_data = hf[\"A_data\"][()]\n",
    "        A_indices = hf[\"A_indices\"][()]\n",
    "        A_indptr = hf[\"A_indptr\"][()]\n",
    "        A_shape = hf[\"A_shape\"][()]\n",
    "        tv_a = hf[\"tuned_vector_angles\"][()]\n",
    "        tv_l = hf[\"tuned_vector_lengths\"][()]\n",
    "        #spatial = ut.read_spatial(A_data, A_indices, A_indptr, A_shape, n_components, resolution, unflatten=False)\n",
    "        spatial = scipy.sparse.csc_matrix((A_data, A_indices, A_indptr), shape=A_shape)\n",
    "        dims_list.append(resolution)\n",
    "        A_list.append(spatial)  # need to swap: (n_units, n_pixels) -> (n_pixels, n_units)\n",
    "        p_vals.append(ps)\n",
    "        conditions.append(condition)\n",
    "        tv_angles.append(tv_a)\n",
    "        tv_lengths.append(tv_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tuned vector data into numpy array. To deal with varying number of units per recording (condition), pad each column to the longest with np.nan\n",
    "max_len = max(len(lst) for lst in tv_angles) \n",
    "def convert_to_np(list_of_arrs):\n",
    "    \"\"\"\n",
    "    given a list of 1D arrays, convert to a 2D array, add padding with np.nans to achieve equal column sizes \n",
    "    \"\"\"\n",
    "    return np.array([np.concatenate([lst, [np.nan]*(max_len - len(lst))]) for lst in list_of_arrs]).T\n",
    "\n",
    "tv_angles_padded = convert_to_np(tv_angles)\n",
    "tv_lengths_padded = convert_to_np(tv_lengths)\n",
    "p_vals_padded = convert_to_np(p_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(templates) > 0:\n",
    "    templates_cropped = []\n",
    "    for template in templates:\n",
    "        FOV_shape = template.shape\n",
    "        cropped_shape = dims_list[0]\n",
    "        \n",
    "        x_crop_onesided = (FOV_shape[0] - cropped_shape[0])//2\n",
    "        assert 2*x_crop_onesided == FOV_shape[0] - cropped_shape[0]\n",
    "\n",
    "        y_crop_onesided = (FOV_shape[1] - cropped_shape[1])//2\n",
    "        assert 2*y_crop_onesided == FOV_shape[1] - cropped_shape[1]\n",
    "        template_cropped = template[y_crop_onesided:-y_crop_onesided,x_crop_onesided:-x_crop_onesided]  # TODO: x and y swapped?\n",
    "        templates_cropped.append(template_cropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `register_multisession()`\n",
    "\n",
    "The function `register_multisession()` requires 3 arguments:\n",
    "- `A`: A list of ndarrays or scipy.sparse.csc matrices with (# pixels X # component ROIs) for each session\n",
    "- `dims`: Dimensions of the FOV, needed to restore spatial components to a 2D image\n",
    "- `templates`: List of ndarray matrices of size `dims`, template image of each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_union, assignments, matchings = register_multisession(A=A_list, dims=dims_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function returns 3 variables for further analysis:\n",
    "- `spatial_union`: csc_matrix (# pixels X # total distinct components), the union of all ROIs across all sessions aligned to the FOV of the last session.\n",
    "- `assignments`: ndarray (# total distinct components X # sessions). `assignments[i,j]=k` means that component `k` from session `j` has been identified as component `i` from the union of all components, otherwise it takes a `NaN` value. Note that for each `i` there is at least one session index `j` where `assignments[i,j]!=NaN`.\n",
    "- `matchings`: list of (# sessions) lists. Saves `spatial_union` indices of individual components in each session. `matchings[j][k] = i` means that component `k` from session `j` is represented by component `i` in the union of all components `spatial_union`. In other words `assignments[matchings[j][k], j] = j`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create various subgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create indices for conditions used\n",
    "assert \"bl\" in conditions  # TODO: not all bl are called bl1! Some bl_d1_1, bl_d1_2, bl_d2...\n",
    "conditions_to_use = [\"bl\", \"30min\", \"60min\"]  \n",
    "i_cond_filtered = np.isin(np.array(conditions), np.array(conditions_to_use))\n",
    "\n",
    "assignments_filtered = assignments[:, i_cond_filtered]\n",
    "assignments_filtered = assignments_filtered[~np.isnan(assignments_filtered).all(axis=1)]  # filter out rows full of np.nan\n",
    "\n",
    "# do not throw away any rows in tuned vector data, but throw away conditions we do not use.\n",
    "# The vector lengths of one unit over different conditions can be accessed with tv_lengths_filtered[]\n",
    "tv_lengths_filtered = tv_lengths_padded[:, i_cond_filtered]\n",
    "tv_angles_filtered = tv_angles_padded[:, i_cond_filtered]\n",
    "p_vals_filtered = p_vals_padded[:, i_cond_filtered]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take only omnipresent cells\n",
    "(omnipresent cell = cell that could be identified in all recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments_omnipresent = assignments_filtered[~np.isnan(assignments_filtered).any(axis=1)].astype(np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match (pair) values for same cell from different conditions (recordings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each omnipresent unit, get the vector length for each included condition\n",
    "tv_lengths_paired = np.zeros(assignments_omnipresent.shape)\n",
    "tv_angles_paired = np.zeros(assignments_omnipresent.shape)\n",
    "p_vals_paired = np.zeros(assignments_omnipresent.shape)\n",
    "for i_cond in range(len(conditions_to_use)):\n",
    "    tv_lengths_paired[:, i_cond] = tv_lengths_filtered[ assignments_omnipresent.T[i_cond],i_cond]\n",
    "    tv_angles_paired[:, i_cond] = tv_angles_filtered[ assignments_omnipresent.T[i_cond],i_cond]\n",
    "    p_vals_paired[:, i_cond] = p_vals_filtered[assignments_omnipresent.T[i_cond], i_cond]\n",
    "\n",
    "# check that np.nans (coming from analysis where cells did not fulfill criteria to be included) match for all variables\n",
    "assert (~np.isnan(p_vals_paired).any(axis=1) == ~np.isnan(tv_angles_paired).any(axis=1) ).all()\n",
    "assert (~np.isnan(p_vals_paired).any(axis=1) == ~np.isnan(tv_lengths_paired).any(axis=1) ).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get persistent cels\n",
    "(persistent cell = omnipresent cell that fulfilled requirement for getting included in place coding analysis for each condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_persistent = ~np.isnan(p_vals_paired).any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_lengths_persistent = tv_lengths_paired[i_persistent]\n",
    "tv_angles_persistent = tv_angles_paired[i_persistent]\n",
    "p_vals_persistent = p_vals_paired[i_persistent]\n",
    "assignments_persistent = assignments_omnipresent[i_persistent]\n",
    "\n",
    "assert tv_lengths_persistent.shape == tv_angles_persistent.shape\n",
    "assert tv_angles_persistent.shape == p_vals_persistent.shape\n",
    "assert p_vals_persistent.shape == assignments_persistent.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `assignments_persistent` contains one row per persistent cell where it fulfilled analysis criteria (minimum number of events...) for all included conditions. For each row, each column contains the original cell index in the recording of the corresponding `conditions_to_use` condition (i.e. `assignments_persistent[0][0]==8` means the first persistent cell is cell 8 (with indexing starting at 0) in the baseline recording. The same cell might be cell 253 in the second condition (`assignments_persistent[0][1]==253`) )\n",
    "* `tv_lengths_persistent`, `tv_angles_persistent`, `p_vals_persistent` contain the tuning vector lengths, angles, and the p value, each row one neuron tracked over the conditions (that fulfilled analysis criteria). The rows and columns match those of `assignments_persistent` (i.e. the same cell, same condition is in the same row and column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get persistent cells that are initially place coding (ipc) and not initially place coding (nipc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_ipc = np.where(p_vals_persistent[:,0] <= 0.05)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_lengths_ipc = tv_lengths_persistent[i_ipc]\n",
    "tv_angles_ipc = tv_angles_persistent[i_ipc]\n",
    "p_vals_ipc = p_vals_persistent[i_ipc]\n",
    "assignments_ipc = assignments_persistent[i_ipc]\n",
    "\n",
    "tv_lengths_nipc = tv_lengths_persistent[~i_ipc]\n",
    "tv_angles_nipc = tv_angles_persistent[~i_ipc]\n",
    "p_vals_nipc = p_vals_persistent[~i_ipc]\n",
    "assignments_nipc = assignments_persistent[~i_ipc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check movement between place-coding, non-place-coding, \"quiet\" cells\n",
    "Quiet cells: cells that were not included in PC analysis (minimum event number criterion not fulfilled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# silent cells appear as np.nan in p_vals. Make sure they return FALSE for both PC and nPC conditions\n",
    "assert not(np.nan > 0.05)\n",
    "assert not(np.nan <= 0.05)\n",
    "assert np.isnan(np.nan)\n",
    "\n",
    "labels = [] \n",
    "colors = []\n",
    "for condition in conditions_to_use:\n",
    "  labels.extend([f\"PC {condition}\", f\"nPC {condition}\", f\"Q {condition}\"])  # for each condition, check categories PC, not-PC and quiet\n",
    "  colors.extend([\"red\", \"blue\", \"black\"])  # 255, 0, 0;  0, 255, 0; 0, 0, 0\n",
    "# in each condition, we have PC and nPC categories, each have PC and nPC targets in the next category\n",
    "sources = []  # should be 0, 1, 2, 0, 1, 2, 0, 1, 2, 3, 4, 5, 3, 4, 5, 3, 4, 5, ...\n",
    "targets = []  # should be 3, 4, 5, 3, 4, 5, 3, 4, 5, 6, 7, 8, 6, 7, 8, 6, 7, 8, ...\n",
    "values = []\n",
    "link_colors = []\n",
    "for i_condition in range(len(conditions_to_use)-1):  # last condition does not have output\n",
    "  # PC, nPC and S sources flow to PC in target\n",
    "  # i. e. PC[i_condition] -> PC[i_condition+1], nPC[i_condition] -> PC[i_condition+1], Q[i_condition] -> PC[i_condition+1]\n",
    "  n_PC_to_PC = np.sum(np.logical_and(p_vals_paired[:,i_condition] <= 0.05,  p_vals_paired[:,i_condition+1] <= 0.05))\n",
    "  n_nPC_to_PC = np.sum(np.logical_and(p_vals_paired[:,i_condition] > 0.05,  p_vals_paired[:,i_condition+1] <= 0.05))\n",
    "  n_quiet_to_PC = np.sum(np.logical_and(np.isnan(p_vals_paired[:, i_condition]), p_vals_paired[:,i_condition+1] <= 0.05))\n",
    "  sources.extend([3*i_condition,3*i_condition+1, 3*i_condition+2])\n",
    "  targets.extend([3*(i_condition+1), 3*(i_condition+1), 3*(i_condition+1)])\n",
    "  values.extend([n_PC_to_PC, n_nPC_to_PC, n_quiet_to_PC])\n",
    "  link_colors.extend([\"rgba(255, 0, 0, 0.4)\", \"rgba(0, 0, 255, 0.4)\", \"rgba(0, 0, 0, 0.4)\"])  # PC -> x is light blue, nPC -> x is light red, Q -> y is \"light black\"\n",
    "\n",
    "  # PC, nPC and Q sources flow to nPC in target\n",
    "  # i. e. PC[i_condition] -> nPC[i_condition+1], nPC[i_condition] -> nPC[i_condition+1], Q[i_condition] -> nPC[i_condition+1]\n",
    "  n_PC_to_nPC = np.sum(np.logical_and(p_vals_paired[:,i_condition] <= 0.05,  p_vals_paired[:,i_condition+1] > 0.05))\n",
    "  n_nPC_to_nPC = np.sum(np.logical_and(p_vals_paired[:,i_condition] > 0.05,  p_vals_paired[:,i_condition+1] > 0.05))\n",
    "  n_quiet_to_nPC = np.sum(np.logical_and(np.isnan(p_vals_paired[:, i_condition]), p_vals_paired[:,i_condition+1] > 0.05))\n",
    "  sources.extend([3*i_condition,3*i_condition+1, 3*i_condition+2])\n",
    "  targets.extend([3*(i_condition+1)+1, 3*(i_condition+1)+1, 3*(i_condition+1)+1])\n",
    "  values.extend([n_PC_to_nPC, n_nPC_to_nPC, n_quiet_to_nPC])\n",
    "  link_colors.extend([\"rgba(255, 0, 0, 0.4)\", \"rgba(0, 0, 255, 0.4)\", \"rgba(0, 0, 0, 0.4)\"])  # PC -> x is light blue, nPC -> x is light red, Q -> y is \"light black\"\n",
    "\n",
    "\n",
    "  # PC, nPC and Q sources flow to S in target\n",
    "  # i. e. PC[i_condition] -> Q[i_condition+1], nPC[i_condition] -> Q[i_condition+1], Q[i_condition] -> Q[i_condition+1]\n",
    "  n_PC_to_Q = np.sum(np.logical_and(p_vals_paired[:,i_condition] <= 0.05,  np.isnan(p_vals_paired[:,i_condition+1]) ))\n",
    "  n_nPC_to_Q = np.sum(np.logical_and(p_vals_paired[:,i_condition] > 0.05,  np.isnan(p_vals_paired[:,i_condition+1])  ))\n",
    "  n_quiet_to_Q = np.sum(np.logical_and(np.isnan(p_vals_paired[:, i_condition]), np.isnan(p_vals_paired[:,i_condition+1])  ))\n",
    "  sources.extend([3*i_condition,3*i_condition+1, 3*i_condition+2])\n",
    "  targets.extend([3*(i_condition+1)+2, 3*(i_condition+1)+2, 3*(i_condition+1)+2])\n",
    "  values.extend([n_PC_to_Q, n_nPC_to_Q, n_quiet_to_Q])\n",
    "  link_colors.extend([\"rgba(255, 0, 0, 0.4)\", \"rgba(0, 0, 255, 0.4)\", \"rgba(0, 0, 0, 0.4)\"])  # PC -> x is light blue, nPC -> x is light red, Q -> y is \"light black\"\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node = dict(\n",
    "      pad = 15,\n",
    "      thickness = 20,\n",
    "      line = dict(color = \"black\", width = 0.5),\n",
    "      label = labels,\n",
    "      color = colors\n",
    "    ),\n",
    "    link = dict(\n",
    "      source = sources, # indices correspond to labels, eg A1, A2, A1, B1, ...\n",
    "      target = targets,\n",
    "      value = values,\n",
    "      color = link_colors\n",
    "  ))])\n",
    "\n",
    "fig.update_layout(title_text=\"Place coding (PC) - non-place coding (nPC) - quiet (Q)\", font_size=10)\n",
    "fig.write_html(\"D:\\\\Downloads\\\\pc_npc_s.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## % of place cells at each time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_cell_ratio = np.zeros(len(p_vals))  # the % of place cells for each condition\n",
    "for i_condition in range(len(p_vals)):\n",
    "    place_cell_ratio[i_condition] = np.sum(p_vals[i_condition] <= 0.05)/len(p_vals[i_condition])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "axs[0].plot(place_cell_ratio*100.)\n",
    "axs[0].set_xticks(range(len(conditions)), conditions)\n",
    "axs[0].set_ylabel(\"% place cells\")\n",
    "\n",
    "axs[1].plot([len(p_vals[i_cond]) for i_cond in range(len(p_vals))])\n",
    "axs[1].set_xticks(range(len(conditions)), conditions)\n",
    "axs[1].set_ylabel(\"# cells (total)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check persistent cells behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [] \n",
    "colors= []\n",
    "for condition in conditions_to_use:\n",
    "  labels.extend([f\"PC {condition}\", f\"nPC {condition}\"])  # for each condition, check categories PC and not-PC\n",
    "  colors.extend([\"red\", \"blue\"])\n",
    "# in each condition, we have PC and nPC categories, each have PC and nPC targets in the next category\n",
    "sources = []  # should be 0, 1, 0, 1, 2, 3, 2, 3, ...\n",
    "targets = []  # should be 2, 3, 2, 3, 4, 5, 4, 5, ...\n",
    "values = []\n",
    "link_colors = []\n",
    "for i_condition in range(len(conditions_to_use)-1):  # last condition does not have output\n",
    "  # PC and nPC sources flow to PC in target\n",
    "  # i. e. PC[i_condition] -> PC[i_condition+1], nPC[i_condition] -> PC[i_condition+1]\n",
    "  n_PC_to_PC = np.sum(np.logical_and(p_vals_persistent[:,i_condition] <= 0.05,  p_vals_persistent[:,i_condition+1] <= 0.05))\n",
    "  n_nPC_to_PC = np.sum(np.logical_and(p_vals_persistent[:,i_condition] > 0.05,  p_vals_persistent[:,i_condition+1] <= 0.05))\n",
    "  sources.extend([2*i_condition,2*i_condition+1])\n",
    "  targets.extend([2*(i_condition+1), 2*(i_condition+1)])\n",
    "  values.extend([n_PC_to_PC, n_nPC_to_PC])\n",
    "  link_colors.extend([\"rgba(255, 0, 0, 0.4)\", \"rgba(0, 0, 255, 0.4)\"])  # PC -> x is light blue, nPC -> x is light red\n",
    "  \n",
    "  # PC and nPC sources flow to nPC in target\n",
    "  # i. e. PC[i_condition] -> nPC[i_condition+1], nPC[i_condition] -> nPC[i_condition+1]\n",
    "  n_PC_to_nPC = np.sum(np.logical_and(p_vals_persistent[:,i_condition] <= 0.05,  p_vals_persistent[:,i_condition+1] > 0.05))\n",
    "  n_nPC_to_nPC = np.sum(np.logical_and(p_vals_persistent[:,i_condition] > 0.05,  p_vals_persistent[:,i_condition+1] > 0.05))\n",
    "  sources.extend([2*i_condition,2*i_condition+1])\n",
    "  targets.extend([2*(i_condition+1)+1, 2*(i_condition+1)+1])\n",
    "  values.extend([n_PC_to_nPC, n_nPC_to_nPC])\n",
    "  link_colors.extend([\"rgba(255, 0, 0, 0.4)\", \"rgba(0, 0, 255, 0.4)\"])  # PC -> x is light blue, nPC -> x is light red\n",
    "\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node = dict(\n",
    "      pad = 15,\n",
    "      thickness = 20,\n",
    "      line = dict(color = \"black\", width = 0.5),\n",
    "      label = labels,\n",
    "      color = colors\n",
    "    ),\n",
    "    link = dict(\n",
    "      source = sources, # indices correspond to labels, eg A1, A2, A1, B1, ...\n",
    "      target = targets,\n",
    "      value = values,\n",
    "      color=link_colors\n",
    "  ))])\n",
    "\n",
    "fig.update_layout(title_text=\"Place coding (PC) - non-place coding (nPC) of persistent cells\", font_size=10)\n",
    "fig.write_html(\"D:\\\\Downloads\\\\pc_npc.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check tuning vector direction change/stability for initially place-coding cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'}, figsize=(6,6))\n",
    "#ax.set_yscale('log')\n",
    "for angles in tv_angles_ipc:\n",
    "    radii = [i+1 for i in range(len(angles))]#tv_vector_lengths_paired[i_unit]\n",
    "    ax.plot(angles, radii, linewidth=0.3, marker='o')  # -pi to pi\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save multisession registration results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spatial_union, assignments, matchings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
